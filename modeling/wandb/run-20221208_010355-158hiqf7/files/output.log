Thu Dec  8 01:04:14 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |
| N/A   29C    P0    48W / 400W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
2022-12-08 01:04:23.635883: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
{'MATH_dataroot': None,
 'MATH_mode': 'mixed_final_boxed_and_full',
 'MATH_peek_max': 1.0,
 'MATH_peek_min': 0.1,
 'arch': 'gpt2',
 'batch_size_per_replica': 16,
 'dataloader_num_workers': 1,
 'deepmind_dataroot': None,
 'epochs': 1,
 'grad_acc_steps': 4,
 'khan_dataroot': '../data_file_lists/amps/khan',
 'khan_latex_mask': False,
 'khan_mode': 'mixed_hints',
 'load': None,
 'local_rank': -1,
 'log_freq': 5,
 'lr': 5e-05,
 'lr_warmup_steps': -1,
 'mathematica_dataroot': '../data_file_lists',
 'processed_khan_dataroot': '../processed_data/khan',
 'processed_mathematica_dataroot': '../processed_data/mathematica',
 'processed_mathematica_steps_dataroot': '../processed_data/mathematica_steps',
 'save_dir': 'checkpoints/TEMP/12-08-2022__01:04:31',
 'save_steps': 0,
 'stackexchange_dataroot': None,
 'tokenizer_merges_file': './merges_gpt2_single_digit_numbers',
 'tpu_num_cores': 8,
 'weight_decay': 0.05}
Downloading: 100% 560/560 [00:00<00:00, 601kB/s]
Downloading: 100% 1.01k/1.01k [00:00<00:00, 874kB/s]
Downloading: 100% 899k/899k [00:00<00:00, 5.14MB/s]
Downloading: 100% 456k/456k [00:00<00:00, 3.02MB/s]
Downloading: 100% 357/357 [00:00<00:00, 342kB/s]
MathematicaMathDataset: Loading processed samples from 1205000 lines.

100% 1205000/1205000 [00:00<00:00, 1880739.73it/s]
MathematicaMathDataset: Loading processed samples from 530000 lines.
100% 530000/530000 [00:00<00:00, 1903361.11it/s]
MathematicaMathDataset: Loading processed samples from 670000 lines.
100% 670000/670000 [00:00<00:00, 1845634.69it/s]
MathematicaMathDataset: Loading processed samples from 300000 lines.

100% 300000/300000 [00:00<00:00, 1532231.15it/s]
MathematicaMathDataset: Loading processed samples from 1200000 lines.
100% 1200000/1200000 [00:00<00:00, 1787186.79it/s]
MathematicaMathDataset: Loading processed samples from 700500 lines.
100% 700500/700500 [00:00<00:00, 1963193.80it/s]
MathematicaMathDataset: Loaded 4605500 samples.
MathematicaWithStepsMathDataset: Loading processed samples from 35000 lines.
100% 35000/35000 [00:00<00:00, 1244568.94it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 10000 lines.
100% 10000/10000 [00:00<00:00, 1161760.52it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 35000 lines.
100% 35000/35000 [00:00<00:00, 1234490.23it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 95000 lines.
100% 95000/95000 [00:00<00:00, 1112364.23it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 50000 lines.
100% 50000/50000 [00:00<00:00, 1355353.48it/s]
MathematicaWithStepsMathDataset: Loaded 225000 samples.
KhanAcademyMathDataset: Loading processed samples from 103059 lines.
100% 103059/103059 [00:00<00:00, 242295.52it/s]
KhanAcademyMathDataset: Loaded 103059 samples.
MathematicaMathDataset: __len__ = 4605500
MathematicaWithStepsMathDataset: __len__ = 225000
KhanAcademyMathDataset: __len__ = 103059
Save Steps =  9635




Downloading: 100% 526M/526M [00:08<00:00, 64.5MB/s]
Setting up Trainer
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
STARTING TRAINING. save_steps=9635
Making AdamW Optimizer
Using constant LR
***** Running training *****
  Num examples = 4933559
  Num Epochs = 1
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 4
  Total optimization steps = 77086
  Number of trainable parameters = 125198592
  File "tune_gpt.py", line 369, in main(most recent call last):
  File "tune_gpt.py", line 378, in <module>
    main()
  File "tune_gpt.py", line 369, in main(most recent call last):
    run_training(args, train_data)
  File "tune_gpt.py", line 114, in run_training
    trainer.train()
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1527, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1775, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 2523, in training_step
    loss = self.compute_loss(model, inputs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 2555, in compute_loss
    outputs = model(**inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 772, in forward
    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py", line 1174, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 3026, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.06 GiB (GPU 0; 39.59 GiB total capacity; 33.11 GiB already allocated; 2.49 GiB free; 35.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
  0% 0/77086 [00:06<?, ?it/s]
2022-12-08 01:07:04.279668: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
{'MATH_dataroot': None,
 'MATH_mode': 'mixed_final_boxed_and_full',
 'MATH_peek_max': 1.0,
 'MATH_peek_min': 0.1,
 'arch': 'gpt2',
 'batch_size_per_replica': 8,
 'dataloader_num_workers': 1,
 'deepmind_dataroot': None,
 'epochs': 1,
 'grad_acc_steps': 4,
 'khan_dataroot': '../data_file_lists/amps/khan',
 'khan_latex_mask': False,
 'khan_mode': 'mixed_hints',
 'load': None,
 'local_rank': -1,
 'log_freq': 5,
 'lr': 5e-05,
 'lr_warmup_steps': -1,
 'mathematica_dataroot': '../data_file_lists',
 'processed_khan_dataroot': '../processed_data/khan',
 'processed_mathematica_dataroot': '../processed_data/mathematica',
 'processed_mathematica_steps_dataroot': '../processed_data/mathematica_steps',
 'save_dir': 'checkpoints/TEMP/12-08-2022__01:07:07',
 'save_steps': 0,
 'stackexchange_dataroot': None,
 'tokenizer_merges_file': './merges_gpt2_single_digit_numbers',
 'tpu_num_cores': 8,
 'weight_decay': 0.05}
MathematicaMathDataset: Loading processed samples from 1205000 lines.
100% 1205000/1205000 [00:00<00:00, 1831104.65it/s]
MathematicaMathDataset: Loading processed samples from 530000 lines.
100% 530000/530000 [00:00<00:00, 1883152.98it/s]
MathematicaMathDataset: Loading processed samples from 670000 lines.
100% 670000/670000 [00:00<00:00, 1802158.78it/s]
MathematicaMathDataset: Loading processed samples from 300000 lines.
100% 300000/300000 [00:00<00:00, 1487051.82it/s]
MathematicaMathDataset: Loading processed samples from 1200000 lines.
100% 1200000/1200000 [00:00<00:00, 1772174.98it/s]
MathematicaMathDataset: Loading processed samples from 700500 lines.
100% 700500/700500 [00:00<00:00, 1952377.82it/s]
MathematicaMathDataset: Loaded 4605500 samples.
MathematicaWithStepsMathDataset: Loading processed samples from 35000 lines.
100% 35000/35000 [00:00<00:00, 1250655.06it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 10000 lines.
100% 10000/10000 [00:00<00:00, 1128107.58it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 35000 lines.
100% 35000/35000 [00:00<00:00, 1234251.51it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 95000 lines.
100% 95000/95000 [00:00<00:00, 1106633.49it/s]
MathematicaWithStepsMathDataset: Loading processed samples from 50000 lines.
100% 50000/50000 [00:00<00:00, 1357520.52it/s]
MathematicaWithStepsMathDataset: Loaded 225000 samples.
KhanAcademyMathDataset: Loading processed samples from 103059 lines.
100% 103059/103059 [00:00<00:00, 238494.10it/s]
KhanAcademyMathDataset: Loaded 103059 samples.
MathematicaMathDataset: __len__ = 4605500
MathematicaWithStepsMathDataset: __len__ = 225000
KhanAcademyMathDataset: __len__ = 103059
Save Steps =  19271
Setting up Trainer
STARTING TRAINING. save_steps=19271
Making AdamW Optimizer
Using constant LR
***** Running training *****
  Num examples = 4933559
  Num Epochs = 1
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 4
  Total optimization steps = 154173
  Number of trainable parameters = 125198592
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
[34m[1mwandb[39m[22m: Currently logged in as: [33mgbhong2[39m. Use [1m`wandb login --relogin`[22m to force relogin
[34m[1mwandb[39m[22m: Tracking run with wandb version 0.13.6
[34m[1mwandb[39m[22m: Run data is saved locally in [35m[1m/content/drive/MyDrive/Colab Notebooks/math/modeling/wandb/run-20221208_010817-1e9gdlfx
[34m[1mwandb[39m[22m: Run [1m`wandb offline`[22m to turn off syncing.
[34m[1mwandb[39m[22m: Syncing run [33mcheckpoints/TEMP/12-08-2022__01:07:07
[34m[1mwandb[39m[22m: ⭐️ View project at [34m[4mhttps://wandb.ai/gbhong2/huggingface
[34m[1mwandb[39m[22m: 🚀 View run at [34m[4mhttps://wandb.ai/gbhong2/huggingface/runs/1e9gdlfx
{'loss': 1.5652, 'learning_rate': 5e-05, 'epoch': 0.0}



{'loss': 1.252, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 1.0734, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 1.0488, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.9539, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.9137, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.8993, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.938, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.8419, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.8427, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.771, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.8151, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7654, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.8171, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7988, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7513, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7366, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7341, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7119, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7422, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.71, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6838, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7323, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6827, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6787, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6847, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6891, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6519, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6623, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6644, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6853, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.7127, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6598, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6648, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6691, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.625, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6442, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6568, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6382, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6291, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6419, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6453, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6412, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5937, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.625, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5989, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6326, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6468, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6063, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6279, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6047, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6251, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6266, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6034, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5946, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6298, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6129, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5678, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6252, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5775, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5978, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.583, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5957, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5977, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6133, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.617, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5713, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5563, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5846, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5833, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.6122, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5803, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5354, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5984, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5734, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5419, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5597, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5627, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5671, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5751, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5405, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5724, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5676, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5894, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5808, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5782, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5769, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5946, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5624, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5184, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5414, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5927, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5915, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5409, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5647, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5691, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5065, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5124, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5542, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5301, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.517, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.59, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4923, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.541, 'learning_rate': 5e-05, 'epoch': 0.0}





  0% 524/154173 [19:49<96:32:02,  2.26s/it]tcmalloc: large alloc 1140858880 bytes == 0x7f08b1ffc000 @  0x7f0b7fff01e7 0x7f0ade80c3bb 0x7f0ade9f64a0 0x7f0ade9dd912 0x7f0adea12413 0x7f0adea09d75 0x7f0ade910225 0x7f0ade9119b5 0x7f0ade911439 0x7f0ade8b45cb 0x7f0ade8e378e 0x7f0ade853c7c 0x7f0ade8e6cad 0x7f0ade93156e 0x7f0ade82c7c5 0x7f0ade911b15 0x7f0ade964549 0x7f0ade959492 0x7f0ade89cb1f 0x7f0ade95c39c 0x5aa114 0x49ced5 0x55e858 0x5d7cf1 0x4fea58 0x5d77c6 0x561051 0x55e858 0x5d7cf1 0x4fea58 0x5d77c6
{'loss': 0.549, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5246, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5559, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5359, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5444, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5786, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5432, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5357, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5251, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5082, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5271, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5439, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5549, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.534, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5253, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5564, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4948, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.555, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5241, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5131, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5404, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.55, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5217, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5285, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5193, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5312, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5338, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4883, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4986, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4963, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4873, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5398, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5255, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4967, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4826, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5228, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5384, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.543, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5403, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5131, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4783, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5022, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5242, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4936, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5196, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5216, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5147, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.509, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.5087, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4903, 'learning_rate': 5e-05, 'epoch': 0.0}




{'loss': 0.4948, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5395, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4863, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5145, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5137, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4798, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4904, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4983, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5039, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5124, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4784, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4848, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.491, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5014, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5346, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5097, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.498, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5242, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4854, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5136, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4845, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.48, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4916, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4843, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5498, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4668, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4859, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4917, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.512, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4584, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5279, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5102, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4693, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.49, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4842, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4889, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4606, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4707, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5171, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4686, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4668, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.454, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4521, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4916, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.462, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4422, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4811, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4668, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4424, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4816, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4767, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.482, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5034, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5019, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.504, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5011, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.494, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5182, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4342, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4984, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.497, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5096, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4869, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4714, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4635, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4965, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4684, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4975, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4533, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5308, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4832, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5163, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4693, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4451, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4464, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4417, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4504, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5033, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4194, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5039, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4718, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4695, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4464, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4552, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4456, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4927, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4567, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4619, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.439, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4845, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4873, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.519, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4701, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5172, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4985, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4197, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.5174, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4907, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4439, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4472, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4928, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4529, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4306, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4479, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.514, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4656, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4575, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4854, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4784, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.456, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4269, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4102, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4733, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4811, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4811, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4791, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4367, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4655, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4659, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4289, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4378, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4903, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4681, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4779, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4352, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4897, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4763, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4372, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4631, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4247, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4762, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4741, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4623, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4496, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4405, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4331, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4668, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.461, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.471, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4485, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4774, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4631, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4334, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4698, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.449, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4528, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4365, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4319, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4561, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4511, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.482, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4632, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.428, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4588, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4573, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4566, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.472, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4898, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4662, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4498, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4598, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4752, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4522, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4569, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4991, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4541, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4635, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4476, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4643, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4925, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4193, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4306, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4472, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4176, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4349, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4166, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.46, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.449, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4681, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.451, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4584, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4554, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4931, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4306, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4257, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4618, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4192, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4162, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4418, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4351, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4337, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4735, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.448, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4372, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4663, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.477, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4667, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4133, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4117, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4496, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4518, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4151, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4041, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4616, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3941, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4393, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4604, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4432, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4186, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4597, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4289, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4526, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.46, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4246, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4256, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4429, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4494, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4402, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.422, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4526, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4134, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4369, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4595, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4594, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4128, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4102, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4561, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4075, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4631, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4473, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.465, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.416, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4381, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4616, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4431, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4523, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4627, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4307, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4229, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4439, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4269, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4214, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4222, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4144, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4269, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4143, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4255, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4186, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4636, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.433, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.396, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4137, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4056, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4281, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4505, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4124, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4352, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4102, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4246, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4498, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3988, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4573, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3866, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4657, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4305, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.429, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3972, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4596, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4352, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4279, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.426, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4174, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4456, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4353, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4151, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4168, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4126, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3856, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.431, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4702, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4249, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4366, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4464, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4213, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4745, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4103, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4536, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4245, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4017, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3844, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4537, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4617, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4556, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4396, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4225, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4604, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3898, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4335, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4456, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4378, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4129, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4166, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4292, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4253, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4518, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4231, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4191, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.4337, 'learning_rate': 5e-05, 'epoch': 0.01}




{'loss': 0.3966, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4325, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4472, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4101, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3963, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.42, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4402, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4437, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4014, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.399, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4379, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4544, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4159, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4142, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4527, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4029, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.395, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3943, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.41, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4432, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.419, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4219, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4591, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4151, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3915, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4037, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4288, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4035, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4225, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4237, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3931, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4151, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4295, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4177, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4108, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4204, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4224, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.416, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3945, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3998, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4362, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4286, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4535, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4178, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4733, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4243, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4191, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4233, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4184, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4516, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4246, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4195, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3997, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4327, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4026, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4006, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3643, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3992, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4189, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.399, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4055, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4196, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4105, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3813, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.433, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.399, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3932, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3947, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4214, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4284, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4128, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4026, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3835, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3948, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4022, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3952, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3911, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4052, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.396, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3647, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4114, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4051, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4176, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4005, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.398, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4544, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4204, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4337, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3901, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4223, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4574, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3935, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4217, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4052, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4046, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3722, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4236, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4189, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4102, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4226, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4118, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3642, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4273, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4004, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4115, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3931, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4286, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.421, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3988, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3989, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.42, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4035, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3936, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.444, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4191, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3855, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3911, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3665, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4425, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4064, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4253, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3802, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4141, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4284, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4233, 'learning_rate': 5e-05, 'epoch': 0.02}
{'loss': 0.398, 'learning_rate': 5e-05, 'epoch': 0.02}



{'loss': 0.4001, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3783, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4005, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4149, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4204, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3977, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4012, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4177, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4143, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4014, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4287, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3853, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3819, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4076, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4253, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3962, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3778, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4363, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3977, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3995, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4085, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3744, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4121, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3765, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3773, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4232, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3983, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3967, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4954, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3913, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4153, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4226, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4109, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4053, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4018, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4209, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4005, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4271, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3871, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4001, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4147, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4352, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4294, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4157, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4162, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4171, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4288, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4069, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4267, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4203, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4151, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3717, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3988, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3925, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4107, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3837, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.388, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4059, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3914, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3957, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3866, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3868, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4177, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3628, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4067, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4003, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3958, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3925, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4024, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3734, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4124, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3867, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4095, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3794, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.386, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4154, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4086, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3878, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4091, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4012, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4019, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3838, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3896, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3669, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4285, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3878, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3939, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4601, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3943, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.375, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3951, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4063, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4037, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3979, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3719, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3866, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4328, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3849, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.396, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3906, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.409, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4228, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4135, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3954, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3996, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3748, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4072, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3751, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4144, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4081, 'learning_rate': 5e-05, 'epoch': 0.02}



{'loss': 0.4006, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4105, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3839, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3878, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3749, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4254, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4008, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3902, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4152, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4175, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3969, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3808, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4292, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3986, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4088, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4045, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.388, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.386, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4077, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3805, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3921, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4182, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.366, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4131, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3724, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3766, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.395, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3957, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3758, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4041, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3885, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3911, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3886, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4222, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3469, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.404, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3923, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4011, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4025, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4043, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4033, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4061, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3999, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4097, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3826, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3873, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3947, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4202, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3991, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.376, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4018, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4297, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4135, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3836, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4124, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.4008, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3561, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3832, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3897, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3635, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3855, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.38, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3603, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.359, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3982, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3802, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3449, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.385, 'learning_rate': 5e-05, 'epoch': 0.02}




{'loss': 0.3792, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3992, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3878, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3863, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3845, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3823, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3827, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.382, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3713, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4044, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3766, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3842, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3877, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3817, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3991, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3678, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3859, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3713, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3784, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3601, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3988, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3839, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4078, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3776, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4302, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3878, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.429, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3885, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3803, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3818, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.402, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3869, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3958, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.406, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3627, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3612, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3766, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3429, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3918, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3875, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3481, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3659, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3803, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3926, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3798, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3851, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3563, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3806, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3806, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4091, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3932, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3666, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3351, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4069, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3913, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3561, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3785, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3991, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.394, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3691, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4089, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4162, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3922, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3943, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3923, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4059, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4044, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.389, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3858, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3456, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3909, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.362, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3931, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3431, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3932, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3818, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3789, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3689, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3984, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4113, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3659, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3611, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3802, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.396, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3913, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4053, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3639, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3862, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.397, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3929, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3696, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4098, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.402, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4203, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3392, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4119, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3823, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3775, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3961, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4071, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3709, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.4219, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3679, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3843, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3718, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3577, 'learning_rate': 5e-05, 'epoch': 0.03}




{'loss': 0.3638, 'learning_rate': 5e-05, 'epoch': 0.03}




  3% 4389/154173 [2:50:01<94:07:42,  2.26s/it]Traceback (most recent call last):
  File "tune_gpt.py", line 378, in <module>
    main()
  File "tune_gpt.py", line 369, in main
    run_training(args, train_data)
  File "tune_gpt.py", line 114, in run_training
    trainer.train()
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1527, in train
    return inner_training_loop(
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 1775, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 2523, in training_step
    loss = self.compute_loss(model, inputs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/trainer.py", line 2555, in compute_loss
    outputs = model(**inputs)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 744, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 623, in forward
    outputs = block(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 328, in forward
    attn_outputs = self.attn(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 280, in forward
    return self.attention(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 243, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
  File "/usr/local/lib/python3.8/dist-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 195, in _attn
    mask_value = torch.tensor(mask_value, dtype=attn_weights.dtype).to(attn_weights.device)
KeyboardInterrupt
  3% 4389/154173 [2:50:03<96:43:50,  2.32s/it]
